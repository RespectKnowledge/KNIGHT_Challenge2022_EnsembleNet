{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knights_new_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GmDO-fjFWTR",
        "outputId": "ab8a66dc-45df-4976-c46a-529bb15711dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-WBoircFpeW",
        "outputId": "301a1473-20e4-43bb-d246-6bc5493729ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "(C) Copyright 2021 IBM Corp.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "   http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "Created on June 30, 2021\n",
        "\"\"\"\n",
        "\n",
        "from typing import Tuple, Any\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torchvision.models.video.resnet import VideoResNet, BasicBlock, Conv3DSimple, BasicStem, model_urls\n",
        "\n",
        "\n",
        "class FuseBackboneResnet3D(VideoResNet):\n",
        "    \"\"\"\n",
        "    3D model classifier (ResNet architecture\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pretrained: bool = False, in_channels: int = 2, name: str = \"r3d_18\") -> None:\n",
        "        \"\"\"\n",
        "        Create 3D ResNet model\n",
        "        :param pretrained: Use pretrained weights\n",
        "        :param in_channels: number of input channels\n",
        "        :param name: model name. currently only 'r3d_18' is supported\n",
        "        \"\"\"\n",
        "        # init parameters per required backbone\n",
        "        init_parameters = {\n",
        "            'r3d_18': {'block': BasicBlock,\n",
        "                       'conv_makers': [Conv3DSimple] * 4,\n",
        "                       'layers': [2, 2, 2, 2],\n",
        "                       'stem': BasicStem},\n",
        "        }[name]\n",
        "        # init original model\n",
        "        super().__init__(**init_parameters)\n",
        "\n",
        "        # load pretrained parameters if required\n",
        "        if pretrained:\n",
        "            state_dict = load_state_dict_from_url(model_urls[name])\n",
        "            self.load_state_dict(state_dict)\n",
        "\n",
        "        # save input parameters\n",
        "        self.pretrained = pretrained\n",
        "        self.in_channels = in_channels\n",
        "        # override the first convolution layer to support any number of input channels\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv3d(self.in_channels, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2),\n",
        "                      padding=(1, 3, 3), bias=False),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def features(self, x: Tensor) -> Any:\n",
        "        \"\"\"\n",
        "        Extract spatial features - given a 3D tensor\n",
        "        :param x: Input tensor - shape: [batch_size, channels, z, y, x]\n",
        "        :return: spatial features - shape [batch_size, n_features, z', y', x']\n",
        "        \"\"\"\n",
        "        x = self.stem(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tuple[Tensor, None, None, None]:  # type: ignore\n",
        "        \"\"\"\n",
        "        Forward pass. 3D global classification given a volume\n",
        "        :param x: Input volume. shape: [batch_size, channels, z, y, x]\n",
        "        :return: logits for global classification. shape: [batch_size, n_classes].\n",
        "        \"\"\"\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fV7xYOUpFhMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=FuseBackboneResnet3D(pretrained=True)\n",
        "import torch\n",
        "inp=torch.rand(2,2,10,128,128)\n",
        "out=model(inp)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJBxSptrm197",
        "outputId": "3d0bb6ca-5401-4c91-976d-93b68da70dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 512, 2, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gmp = nn.AdaptiveMaxPool3d(output_size=1)\n",
        "outm=gmp(out)\n",
        "print(outm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9T65Julyg5B",
        "outputId": "93450c75-f4cd-41fb-d1da-6eac9f4ac37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 512, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import redirect_stderr\n",
        "import torch.nn as nn\n",
        "gmp = nn.AdaptiveMaxPool3d(output_size=1)\n",
        "outm=gmp(out)\n",
        "outms=torch.squeeze(outm,axis=2)\n",
        "print(outms.shape)\n",
        "rr=torch.rand(1,512,1,1,1)\n",
        "c1=nn.Conv3d(512, 256, kernel_size=1)\n",
        "outc=c1(rr)\n",
        "print(outc.shape)\n",
        "conv_classifier_3d = nn.Sequential(nn.Conv3d(512, 256, kernel_size=1),\n",
        "            nn.ReLU(),nn.Dropout3d(p=0.5), nn.Conv3d(256, 3, kernel_size=1),\n",
        "            )\n",
        "outcm=conv_classifier_3d(outm)\n",
        "#outclass=outcm(outm)\n",
        "print(outcm.shape)\n",
        "do = nn.Dropout3d(p=0.5)\n",
        "logits=outcm\n",
        "logits = logits.squeeze(dim=4)\n",
        "logits = logits.squeeze(dim=3)\n",
        "logits = logits.squeeze(dim=2)\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccDaxINnDEZ",
        "outputId": "fdbc1522-4552-49e4-82b3-163eb9544328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 256, 1, 1, 1])\n",
            "torch.Size([1, 3, 1, 1, 1])\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3GUguVAnocQ",
        "outputId": "bc285412-efdb-4d7e-96e0-40980d75b70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Sequence\n",
        "import torch.nn as nn\n",
        "class ClassifierMLP(nn.Module):\n",
        "    def __init__(self, in_ch: int, num_classes: Optional[int], layers_description: Sequence[int]=(256,128), dropout_rate: float = 0.1):\n",
        "        super().__init__()\n",
        "        layer_list = []\n",
        "        layer_list.append(nn.Linear(in_ch, layers_description[0]))\n",
        "        layer_list.append(nn.ReLU())\n",
        "        if dropout_rate is not None and dropout_rate > 0:\n",
        "            layer_list.append(nn.Dropout(p=dropout_rate))\n",
        "        last_layer_size = layers_description[0]\n",
        "        for curr_layer_size in layers_description[1:]:\n",
        "            layer_list.append(nn.Linear(last_layer_size, curr_layer_size))\n",
        "            layer_list.append(nn.ReLU())\n",
        "            if dropout_rate is not None and dropout_rate > 0:\n",
        "                layer_list.append(nn.Dropout(p=dropout_rate))\n",
        "            last_layer_size = curr_layer_size\n",
        "        \n",
        "        if num_classes is not None:\n",
        "            layer_list.append(nn.Linear(last_layer_size, num_classes))\n",
        "        \n",
        "        self.classifier = nn.Sequential(*layer_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "modelnlpnew=ClassifierMLP(11,num_classes=None)\n",
        "#print(modelnlpnew)"
      ],
      "metadata": {
        "id": "xOY61hV5sI7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelnlpnew=ClassifierMLP(11,num_classes=None)\n",
        "inp=torch.rand(2,11)\n",
        "outnew=modelnlpnew(inp)\n",
        "#outnew=model(inp)\n",
        "print(outnew.shape)\n",
        "features = outnew.reshape(outnew.shape + (1,1,1))\n",
        "print(features.shape)\n",
        "outm\n",
        "global_features = torch.cat((outm, features), dim=1)\n",
        "print(global_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmaAwDQ0wzzC",
        "outputId": "b0639ccc-f3cd-4587-e57f-9c1bbb2c97e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 128])\n",
            "torch.Size([2, 128, 1, 1, 1])\n",
            "torch.Size([2, 640, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierMLP(nn.Module):\n",
        "    def __init__(self, in_ch: 512, num_classes: 3, layers_description=[256], dropout_rate: float = 0.1):\n",
        "        super().__init__()\n",
        "        layer_list = []\n",
        "        layer_list.append(nn.Linear(in_ch, layers_description[0]))\n",
        "        layer_list.append(nn.ReLU())\n",
        "        if dropout_rate is not None and dropout_rate > 0:\n",
        "            layer_list.append(nn.Dropout(p=dropout_rate))\n",
        "        last_layer_size = layers_description[0]\n",
        "        for curr_layer_size in layers_description[1:]:\n",
        "            layer_list.append(nn.Linear(last_layer_size, curr_layer_size))\n",
        "            layer_list.append(nn.ReLU())\n",
        "            if dropout_rate is not None and dropout_rate > 0:\n",
        "                layer_list.append(nn.Dropout(p=dropout_rate))\n",
        "            last_layer_size = curr_layer_size\n",
        "        \n",
        "        if num_classes is not None:\n",
        "            layer_list.append(nn.Linear(last_layer_size, num_classes))\n",
        "        \n",
        "        self.classifier = nn.Sequential(*layer_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "modelnlp=ClassifierMLP(3,num_classes=3)\n"
      ],
      "metadata": {
        "id": "OCzutqXcqnE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(modelnlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYAWhUXNrjGG",
        "outputId": "4ced54e1-3711-446c-f3b6-05158e7d9a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassifierMLP(\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "(C) Copyright 2021 IBM Corp.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "   http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "Created on June 30, 2021\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Tuple, Sequence, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from fuse.utils.utils_hierarchical_dict import FuseUtilsHierarchicalDict\n",
        "from fuse.models.heads.common import ClassifierMLP\n",
        "\n",
        "\n",
        "class FuseHead3dClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Model that capture slice feature including the 3D context given the local feature about a slice.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_name: str = 'head_0',\n",
        "                 conv_inputs: Sequence[Tuple[str, int]] = (('model.backbone_features', 512),),\n",
        "                 dropout_rate: float = 0.1,\n",
        "                 num_classes: int = 3,\n",
        "                 append_features: Optional[Tuple[str, int]] = None,\n",
        "                 layers_description: Sequence[int] = (256,), \n",
        "                 append_layers_description: Sequence[int] = tuple(),\n",
        "                 append_dropout_rate: float = 0.0,\n",
        "                 fused_dropout_rate: float = 0.0,\n",
        "                 ) -> None:\n",
        "        \"\"\"\n",
        "        Create simple 3D context model\n",
        "        :param head_name: string representing the head name\n",
        "        :param conv_inputs: Sequence of tuples, each indication features name in batch_dict and size of features (channels)\n",
        "        :param dropout_rate: dropout fraction\n",
        "        :param num_classes: number of output classes\n",
        "        :param append_features: Sequence of tuples, each indication features name in batch_dict and size of features (channels).\n",
        "                                Those are global features that appended after the global max pooling operation\n",
        "        :param layers_description:          Layers description for the classifier module - sequence of hidden layers sizes (Not used currently)\n",
        "        :param append_layers_description: Layers description for the tabular data, before the concatination with the features extracted from the image - sequence of hidden layers sizes\n",
        "        :param append_dropout_rate: Dropout rate for tabular layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # save input params\n",
        "        self.head_name = head_name\n",
        "        self.conv_inputs = conv_inputs\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_classes = num_classes\n",
        "        self.append_features = append_features\n",
        "        self.gmp = nn.AdaptiveMaxPool3d(output_size=1)\n",
        "        self.features_size = sum([features[1] for features in self.conv_inputs]) if self.conv_inputs is not None else 0\n",
        "\n",
        "        # calc appended feature size if used\n",
        "        if self.append_features is not None:\n",
        "            if len(append_layers_description) == 0:\n",
        "                self.features_size += sum([post_concat_input[1] for post_concat_input in append_features])\n",
        "                self.append_features_module = nn.Identity()\n",
        "            else:\n",
        "                self.features_size += append_layers_description[-1]\n",
        "                self.append_features_module = ClassifierMLP(in_ch=sum([post_concat_input[1] for post_concat_input in append_features]),\n",
        "                                                    num_classes=None,\n",
        "                                                    layers_description=append_layers_description,\n",
        "                                                    dropout_rate=append_dropout_rate)                \n",
        "\n",
        "        self.conv_classifier_3d = nn.Sequential(\n",
        "            nn.Conv3d(self.features_size, 256, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout3d(p=fused_dropout_rate), \n",
        "            nn.Conv3d(256, self.num_classes, kernel_size=1),\n",
        "        )\n",
        "\n",
        "        self.do = nn.Dropout3d(p=self.dropout_rate)\n",
        "    \n",
        "    def forward(self, batch_dict: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "        :param batch_dict: dictionary containing an input tensor representing spatial features with 3D context. shape: [batch_size, in_features, z, y, x]\n",
        "        :return: batch dict with fields model.outputs and model.logits\n",
        "        \"\"\"\n",
        "        if self.conv_inputs is not None:\n",
        "            conv_input = torch.cat(\n",
        "                [FuseUtilsHierarchicalDict.get(batch_dict, conv_input[0]) for conv_input in self.conv_inputs], dim=1)\n",
        "            global_features = self.gmp(conv_input)\n",
        "            # save global max pooling features in case needed (mostly to analyze)\n",
        "            FuseUtilsHierarchicalDict.set(batch_dict, 'model.' + self.head_name +'.gmp_features', global_features.squeeze(dim=4).squeeze(dim=3).squeeze(dim=2))\n",
        "            # backward compatibility\n",
        "            if hasattr(self, 'do'):\n",
        "                global_features = self.do(global_features)\n",
        "        # append global features if are used\n",
        "        if self.append_features is not None:\n",
        "            features = torch.cat(\n",
        "                [FuseUtilsHierarchicalDict.get(batch_dict, features[0]).reshape(-1, features[1]) for features in self.append_features], dim=1)\n",
        "            features = self.append_features_module(features)\n",
        "            features = features.reshape(features.shape + (1,1,1))\n",
        "            if self.conv_inputs is not None:\n",
        "                global_features = torch.cat((global_features, features), dim=1)\n",
        "            else:\n",
        "                global_features = features\n",
        "\n",
        "        logits = self.conv_classifier_3d(global_features)\n",
        "        logits = logits.squeeze(dim=4)\n",
        "        logits = logits.squeeze(dim=3)\n",
        "        logits = logits.squeeze(dim=2)  # squeeze will change the shape to  [batch_size, channels']\n",
        "\n",
        "        cls_preds = F.softmax(logits, dim=1)\n",
        "        FuseUtilsHierarchicalDict.set(batch_dict, 'model.logits.' + self.head_name, logits)\n",
        "        FuseUtilsHierarchicalDict.set(batch_dict, 'model.output.' + self.head_name, cls_preds)\n",
        "\n",
        "        return batch_dict"
      ],
      "metadata": {
        "id": "lCBIKpwQm2Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "batch_dict = {'pred': torch.randn(3, 5, requires_grad=True),\n",
        "              'gt': torch.empty(3, dtype=torch.long).random_(5),\n",
        "                'batch_loss_kwargs': {'reduction': 'mean', 'ignore_index': 0}}"
      ],
      "metadata": {
        "id": "tXnsBQ7btNNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_dict['batch_loss_kwargs']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkeogjRTtRj1",
        "outputId": "903d149e-6d28-42ba-93f9-e22ef36d35d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ignore_index': 0, 'reduction': 'mean'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Dict, Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "#from fuse.losses.loss_base import FuseLossBase\n",
        "#from fuse.utils.utils_hierarchical_dict import FuseUtilsHierarchicalDict\n",
        "import torch\n",
        "from typing import Any, Set, Callable, Optional, List, Sequence, Union\n",
        "\n",
        "import numpy\n",
        "import torch\n",
        "\n",
        "\n",
        "class FuseUtilsHierarchicalDict:\n",
        "    @classmethod\n",
        "    def get(cls, hierarchical_dict: dict, key: str):\n",
        "        \"\"\"\n",
        "        get(dict, 'x.y.z') <==> dict['x']['y']['z']\n",
        "        \"\"\"\n",
        "        # split according to '.'\n",
        "        hierarchical_key = key.split('.')\n",
        "\n",
        "        # go over the the dictionary towards the requested value\n",
        "        try:\n",
        "            value = hierarchical_dict[hierarchical_key[0]]\n",
        "            for sub_key in hierarchical_key[1:]:\n",
        "                value = value[sub_key]\n",
        "            return value\n",
        "        except:\n",
        "            flat_dict = FuseUtilsHierarchicalDict.flatten(hierarchical_dict)\n",
        "            if key in flat_dict:\n",
        "                return flat_dict[key]\n",
        "            else:\n",
        "                raise KeyError(f'key {key} does not exist\\n. Possible keys are: {str(list(flat_dict.keys()))}')\n",
        "\n",
        "    @classmethod\n",
        "    def set(cls, hierarchical_dict: dict, key: str, value: Any) -> None:\n",
        "        \"\"\"\n",
        "        set(dict, 'x.y.z', value) <==> dict['x']['y']['z'] = value\n",
        "        If either 'x', 'y' or 'z' nodes do not exist, this function will create them\n",
        "        \"\"\"\n",
        "        # split according to '.'\n",
        "        hierarchical_key = key.split('.')\n",
        "\n",
        "        # go over the the dictionary according to the path, create the nodes that does not exist\n",
        "        element = hierarchical_dict\n",
        "        for key in hierarchical_key[:-1]:\n",
        "            if key not in element:\n",
        "                element[key] = {}\n",
        "            element = element[key]\n",
        "\n",
        "        # set the value\n",
        "        element[hierarchical_key[-1]] = value\n",
        "\n",
        "    @classmethod\n",
        "    def get_all_keys(cls, hierarchical_dict: dict, include_values: bool = False) -> Union[List[str], dict]:\n",
        "        \"\"\"\n",
        "        Get all hierarchical keys in  hierarchical_dict\n",
        "        \"\"\"\n",
        "        all_keys = {}\n",
        "        for key in hierarchical_dict:\n",
        "            if isinstance(hierarchical_dict[key], dict):\n",
        "                all_sub_keys = FuseUtilsHierarchicalDict.get_all_keys(hierarchical_dict[key], include_values=True)\n",
        "                keys_to_add = {f'{key}.{sub_key}':all_sub_keys[sub_key] for sub_key in all_sub_keys}\n",
        "                all_keys.update(keys_to_add)\n",
        "            else:\n",
        "                all_keys[key] = hierarchical_dict[key]\n",
        "        if include_values:\n",
        "            return all_keys\n",
        "        else:\n",
        "            return list(all_keys.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def subkey(cls, key: str, start: int, end: Optional[int]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Sub string of hierarchical key.\n",
        "        Example: subkey('a.b.c.d.f', 1, 3) -> 'b.c'\n",
        "        :param key: the original key\n",
        "        :param start: start index\n",
        "        :param end: end index, not including\n",
        "        :return: str\n",
        "        \"\"\"\n",
        "        key_parts = key.split('.')\n",
        "\n",
        "        # if end not specified set to max.\n",
        "        if end is None:\n",
        "            end = len(key_parts)\n",
        "\n",
        "        if len(key_parts) < start or len(key_parts) < end:\n",
        "            return None\n",
        "\n",
        "        res = '.'.join(key_parts[start:end])\n",
        "        return res\n",
        "\n",
        "    @classmethod\n",
        "    def apply_on_all(cls, hierarchical_dict: dict, apply_func: Callable, *args: Any) -> None:\n",
        "        all_keys = cls.get_all_keys(hierarchical_dict)\n",
        "        for key in all_keys:\n",
        "            new_value = apply_func(cls.get(hierarchical_dict, key), *args)\n",
        "            cls.set(hierarchical_dict, key, new_value)\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def flatten(cls, hierarchical_dict: dict) -> dict:\n",
        "        \"\"\"\n",
        "        Flatten the dict\n",
        "        @param hierarchical_dict: dict to flatten\n",
        "        @return: dict where keys are the hierarchical_dict keys separated by periods.\n",
        "        \"\"\"\n",
        "        flat_dict = {}\n",
        "        return cls.get_all_keys(hierarchical_dict, include_values=True)\n",
        "\n",
        "    @classmethod\n",
        "    def indices(cls, hierarchical_dict: dict, indices: List[int]) -> dict:\n",
        "        \"\"\"\n",
        "        Extract the specified indices from each element in the dictionary (if possible)\n",
        "        :param hierarchical_dict: input dict\n",
        "        :param indices: indices to extract\n",
        "        :return: dict with only the required indices\n",
        "        \"\"\"\n",
        "        new_dict = {}\n",
        "        all_keys = cls.get_all_keys(hierarchical_dict)\n",
        "        for key in all_keys:\n",
        "            value = cls.get(hierarchical_dict, key)\n",
        "            if isinstance(value, numpy.ndarray) or isinstance(value, torch.Tensor):\n",
        "                new_value = value[indices]\n",
        "            elif isinstance(value, Sequence):\n",
        "                new_value =[item for i, item in enumerate(value) if indices[i]]\n",
        "            else:\n",
        "                new_value = value\n",
        "            cls.set(new_dict, key, new_value)\n",
        "        return new_dict\n",
        "\n",
        "    @classmethod\n",
        "    def to_string(cls, hierarchical_dict: dict) -> str:\n",
        "        \"\"\"\n",
        "        Get flat string including thr content of the dictionary\n",
        "        :param hierarchical_dict: input dict\n",
        "        :return: string\n",
        "        \"\"\"\n",
        "        keys = cls.get_all_keys(hierarchical_dict)\n",
        "        keys = sorted(keys)\n",
        "        res = ''\n",
        "        for key in keys:\n",
        "            res += f'{key} = {FuseUtilsHierarchicalDict.get(hierarchical_dict, key)}\\n'\n",
        "\n",
        "        return res\n",
        "\n",
        "    @classmethod\n",
        "    def pop(cls, hierarchical_dict: dict, key:str):\n",
        "        \"\"\"\n",
        "        return the value hierarchical_dict[key] and remove the key from the dict.\n",
        "        :param hierarchical_dict: the dictionary\n",
        "        :param key: the key to return and remove\n",
        "        \"\"\"\n",
        "        # split according to '.'\n",
        "        hierarchical_key = key.split('.')\n",
        "        # go over the the dictionary towards the requested value\n",
        "        try:\n",
        "            key_idx = len(hierarchical_key) - 1\n",
        "            value = hierarchical_dict[hierarchical_key[0]] if key_idx > 0 else hierarchical_dict\n",
        "            for sub_key in hierarchical_key[1:-1]:\n",
        "                value = value[sub_key]\n",
        "            return value.pop(hierarchical_key[key_idx])\n",
        "        except:\n",
        "            flat_dict = FuseUtilsHierarchicalDict.flatten(hierarchical_dict)\n",
        "            if key in flat_dict:\n",
        "                return flat_dict[key]\n",
        "            else:\n",
        "                raise KeyError(f'key {key} does not exist\\n. Possible keys are: {str(list(flat_dict.keys()))}')\n",
        "\n",
        "    @classmethod\n",
        "    def is_in(cls, hierarchical_dict: dict, key:str) -> bool:\n",
        "        \"\"\"\n",
        "        Returns True if the full key is in dict, False otherwise.\n",
        "        e.g., for dict = {'a':1, 'b.c':2} is_in(dict, 'b.c') returns True, but is_in(dict, 'c') returns False.\n",
        "        :param hierarchical_dict: dict to check\n",
        "        :param key: key to search\n",
        "        :return: key in hierarchical_dict\n",
        "        \"\"\"\n",
        "        return key in cls.get_all_keys(hierarchical_dict)\n",
        "\n",
        "\n",
        "class FuseLossBase(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for Fuse loss functions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 pred_name: str = None,\n",
        "                 target_name: str = None,\n",
        "                 weight: float = 1.0, ) -> None:\n",
        "        super().__init__()\n",
        "        self.pred_name = pred_name\n",
        "        self.target_name = target_name\n",
        "        self.weight = weight\n",
        "\n",
        "class FuseLossDefault(FuseLossBase):\n",
        "    \"\"\"\n",
        "    Default Fuse loss function\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 pred_name: str = None,\n",
        "                 target_name: str = None,\n",
        "                 batch_kwargs_name: str = None,\n",
        "                 callable: Callable = None,\n",
        "                 sample_weight_name: Optional[str] = None,\n",
        "                 weight: float = 1.0,\n",
        "                 filter_func: Optional[Callable] = None,\n",
        "                 **kwargs\n",
        "                 ) -> None:\n",
        "        \"\"\"\n",
        "        This class wraps a PyTorch loss function with a Fuse api.\n",
        "        :param pred_name:               batch_dict key for prediction (e.g., network output)\n",
        "        :param target_name:             batch_dict key for target (e.g., ground truth label)\n",
        "        :param batch_kwargs_name:       batch_dict key for additional, ad-hoc kwargs for loss function\n",
        "                                        Note: batch_kwargs will be merged into other loss function kwargs\n",
        "        :param sample_weight_name       batch_dict key that holds the sample weight for loss summation\n",
        "        :param callable:                PyTorch loss function handle (e.g., torch.nn.functional.cross_entropy)\n",
        "        :param weight:                  Weight multiplier for final loss value\n",
        "        :param filter_func:             function that filters batch_dict/ The function gets ans input batch_dict and returns filtered batch_dict\n",
        "        :param kwargs:                  kwargs for PyTorch loss function\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.pred_name = pred_name\n",
        "        self.target_name = target_name\n",
        "        self.batch_kwargs_name = batch_kwargs_name\n",
        "        self.callable = callable\n",
        "        self.sample_weight_name = sample_weight_name\n",
        "        self.weight = weight\n",
        "        self.filter_func = filter_func\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __call__(self, batch_dict: Dict) -> torch.Tensor:\n",
        "        # filter batch_dict if required\n",
        "        if self.filter_func is not None:\n",
        "            batch_dict = self.filter_func(batch_dict)\n",
        "        preds = FuseUtilsHierarchicalDict.get(batch_dict, self.pred_name)\n",
        "        targets = FuseUtilsHierarchicalDict.get(batch_dict, self.target_name)\n",
        "        batch_kwargs = FuseUtilsHierarchicalDict.get(batch_dict, self.batch_kwargs_name) if self.batch_kwargs_name is not None else {}\n",
        "        kwargs_copy = self.kwargs.copy()\n",
        "        kwargs_copy.update(batch_kwargs)\n",
        "        if self.sample_weight_name is not None:\n",
        "            assert 'reduction' not in kwargs_copy.keys(), 'reduction is forced to none when applying sample weight'\n",
        "            kwargs_copy.update({'reduction': 'none'})\n",
        "        loss_obj = self.callable(preds, targets, **kwargs_copy) * self.weight\n",
        "        if self.sample_weight_name is not None:\n",
        "            sample_weight = FuseUtilsHierarchicalDict.get(batch_dict, self.sample_weight_name)\n",
        "            weighted_loss = loss_obj*sample_weight\n",
        "            loss_obj = torch.mean(weighted_loss)\n",
        "\n",
        "        return loss_obj\n",
        "\n",
        "loss = FuseLossDefault(pred_name='pred',\n",
        "                           target_name='gt',\n",
        "                           batch_kwargs_name='batch_loss_kwargs',\n",
        "                           callable=torch.nn.functional.cross_entropy,\n",
        "                          weight=1.0,\n",
        "                           reduction='sum')\n",
        "\n",
        "res = loss(batch_dict)\n",
        "print('Loss output = ' + str(res))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVX3QZP7tkLN",
        "outputId": "a09b0c02-88f6-4996-8d5a-04b1393aff37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss output = tensor(1.8709, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "batch_dict = {'pred': torch.randn(3, 5, requires_grad=True),\n",
        "                  'gt': torch.empty(3, dtype=torch.long).random_(5),\n",
        "                  'batch_loss_kwargs': {'reduction': 'mean', 'ignore_index': 0}}\n",
        "\n",
        "loss = FuseLossDefault(pred_name='pred',\n",
        "                           target_name='gt',\n",
        "                           batch_kwargs_name='batch_loss_kwargs',\n",
        "                           callable=torch.nn.functional.cross_entropy,\n",
        "                           weight=1.0,\n",
        "                           reduction='sum')\n",
        "\n",
        "res = loss(batch_dict)\n",
        "print('Loss output = ' + str(res))"
      ],
      "metadata": {
        "id": "8lLDRz2Euodk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}